{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:08.212659Z",
     "iopub.status.busy": "2020-08-02T11:53:08.209843Z",
     "iopub.status.idle": "2020-08-02T11:53:08.224115Z",
     "shell.execute_reply": "2020-08-02T11:53:08.222790Z",
     "shell.execute_reply.started": "2020-08-02T11:53:08.212425Z"
    }
   },
   "outputs": [],
   "source": [
    "##gradients are essential for model optmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:08.226856Z",
     "iopub.status.busy": "2020-08-02T11:53:08.226256Z",
     "iopub.status.idle": "2020-08-02T11:53:09.475675Z",
     "shell.execute_reply": "2020-08-02T11:53:09.474578Z",
     "shell.execute_reply.started": "2020-08-02T11:53:08.226794Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:09.478035Z",
     "iopub.status.busy": "2020-08-02T11:53:09.477561Z",
     "iopub.status.idle": "2020-08-02T11:53:09.499658Z",
     "shell.execute_reply": "2020-08-02T11:53:09.488037Z",
     "shell.execute_reply.started": "2020-08-02T11:53:09.477980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1738, -0.4091,  2.1841])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:09.502118Z",
     "iopub.status.busy": "2020-08-02T11:53:09.501704Z",
     "iopub.status.idle": "2020-08-02T11:53:09.528583Z",
     "shell.execute_reply": "2020-08-02T11:53:09.522059Z",
     "shell.execute_reply.started": "2020-08-02T11:53:09.502068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6425, 0.2787, 0.4399])\n"
     ]
    }
   ],
   "source": [
    "b = torch.rand(3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rand() returns random values between 0 and 1. The random values would follow a uniform distribution and hence the mean value would be 0.5\n",
    "\n",
    "randn() returns random values between -infinity and +inifinity. The random values would follow a normal distribution with a mean value 0 and a standard deviation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:09.530500Z",
     "iopub.status.busy": "2020-08-02T11:53:09.530099Z",
     "iopub.status.idle": "2020-08-02T11:53:09.565708Z",
     "shell.execute_reply": "2020-08-02T11:53:09.556220Z",
     "shell.execute_reply.started": "2020-08-02T11:53:09.530446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7121, -0.2480, -1.8401], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True) #-> default is False\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:09.567941Z",
     "iopub.status.busy": "2020-08-02T11:53:09.567290Z",
     "iopub.status.idle": "2020-08-02T11:53:09.585904Z",
     "shell.execute_reply": "2020-08-02T11:53:09.583867Z",
     "shell.execute_reply.started": "2020-08-02T11:53:09.567589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7121, 1.7520, 0.1599], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:09.587508Z",
     "iopub.status.busy": "2020-08-02T11:53:09.587168Z",
     "iopub.status.idle": "2020-08-02T11:53:09.601062Z",
     "shell.execute_reply": "2020-08-02T11:53:09.599730Z",
     "shell.execute_reply.started": "2020-08-02T11:53:09.587465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8858, 1.3429, 2.3440], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_add = a + y\n",
    "z_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:53:09.602614Z",
     "iopub.status.busy": "2020-08-02T11:53:09.602375Z",
     "iopub.status.idle": "2020-08-02T11:53:09.610239Z",
     "shell.execute_reply": "2020-08-02T11:53:09.608461Z",
     "shell.execute_reply.started": "2020-08-02T11:53:09.602586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14.7107,  6.1389,  0.0511], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z_mul = y*y*2\n",
    "print(z_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:54:10.520041Z",
     "iopub.status.busy": "2020-08-02T11:54:10.519707Z",
     "iopub.status.idle": "2020-08-02T11:54:10.530202Z",
     "shell.execute_reply": "2020-08-02T11:54:10.528428Z",
     "shell.execute_reply.started": "2020-08-02T11:54:10.520001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5413, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z_mean = y.mean()\n",
    "print(z_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the gradient\n",
    "##### If the requires_grad is set to False then the .backward() shows error\n",
    "##### Behind the scene during the .backward(), creates the vectorjacobian products(chain rule) and get the final gradients.\n",
    "#### NB: grad can be implicitly created only for scalar outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:54:14.288070Z",
     "iopub.status.busy": "2020-08-02T11:54:14.287485Z",
     "iopub.status.idle": "2020-08-02T11:54:14.296356Z",
     "shell.execute_reply": "2020-08-02T11:54:14.293458Z",
     "shell.execute_reply.started": "2020-08-02T11:54:14.287983Z"
    }
   },
   "outputs": [],
   "source": [
    "z_mean.backward() #dz_mean/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:54:19.406514Z",
     "iopub.status.busy": "2020-08-02T11:54:19.406071Z",
     "iopub.status.idle": "2020-08-02T11:54:19.416960Z",
     "shell.execute_reply": "2020-08-02T11:54:19.415535Z",
     "shell.execute_reply.started": "2020-08-02T11:54:19.406461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333])\n"
     ]
    }
   ],
   "source": [
    "#x now has the .grad attribute that has all the gradients calculated\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways to prevent pytorch from tracking the gradients\n",
    "    * call the requires_grad(False)\n",
    "    * call the .detach()\n",
    "    * wrapping with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:54:22.279493Z",
     "iopub.status.busy": "2020-08-02T11:54:22.278701Z",
     "iopub.status.idle": "2020-08-02T11:54:22.291428Z",
     "shell.execute_reply": "2020-08-02T11:54:22.290316Z",
     "shell.execute_reply.started": "2020-08-02T11:54:22.279431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7121, -0.2480, -1.8401], requires_grad=True)\n",
      "tensor([ 0.7121, -0.2480, -1.8401])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "x.requires_grad_(False)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:54:24.324852Z",
     "iopub.status.busy": "2020-08-02T11:54:24.324398Z",
     "iopub.status.idle": "2020-08-02T11:54:24.335849Z",
     "shell.execute_reply": "2020-08-02T11:54:24.334618Z",
     "shell.execute_reply.started": "2020-08-02T11:54:24.324797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0601,  0.6534,  1.3868, -0.2363, -1.5331], requires_grad=True)\n",
      "tensor([ 1.0601,  0.6534,  1.3868, -0.2363, -1.5331])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, requires_grad=True)\n",
    "print(x)\n",
    "y = x.detach()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:54:25.776820Z",
     "iopub.status.busy": "2020-08-02T11:54:25.776366Z",
     "iopub.status.idle": "2020-08-02T11:54:25.789600Z",
     "shell.execute_reply": "2020-08-02T11:54:25.787836Z",
     "shell.execute_reply.started": "2020-08-02T11:54:25.776766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5113,  0.3730,  1.0853, -0.8524], requires_grad=True)\n",
      "tensor([1.4887, 2.3730, 3.0853, 1.1476])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)\n",
    "print(x)\n",
    "with torch.no_grad():\n",
    "    y = x +2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very important -> gradients keep accumulating so keep closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:55:43.428706Z",
     "iopub.status.busy": "2020-08-02T11:55:43.428385Z",
     "iopub.status.idle": "2020-08-02T11:55:43.439593Z",
     "shell.execute_reply": "2020-08-02T11:55:43.436592Z",
     "shell.execute_reply.started": "2020-08-02T11:55:43.428670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(5, requires_grad=True)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:55:45.129376Z",
     "iopub.status.busy": "2020-08-02T11:55:45.129005Z",
     "iopub.status.idle": "2020-08-02T11:55:45.142254Z",
     "shell.execute_reply": "2020-08-02T11:55:45.140715Z",
     "shell.execute_reply.started": "2020-08-02T11:55:45.129333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As clearly, we see that the gradients keep on accumulating in each epoch, so must be very careful and zero the gradients after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T11:57:57.989750Z",
     "iopub.status.busy": "2020-08-02T11:57:57.989291Z",
     "iopub.status.idle": "2020-08-02T11:57:58.002925Z",
     "shell.execute_reply": "2020-08-02T11:57:58.000994Z",
     "shell.execute_reply.started": "2020-08-02T11:57:57.989708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how it looks in real trainig in pytorch\n",
    "#dummy example\n",
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-02T12:21:51.368004Z",
     "iopub.status.busy": "2020-08-02T12:21:51.367689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 02-gradient_with_autograd.ipynb to script\n",
      "[NbConvertApp] Executing notebook with kernel: python3\n",
      "[NbConvertApp] Writing 2375 bytes to 02-gradient_with_autograd.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --execute --to script 02-gradient_with_autograd.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
